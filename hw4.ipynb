{
 "metadata": {
  "name": "",
  "signature": "sha256:acea89d2604c0623e7802fb900551c3702d8763566a7882941c47c766ba44bb3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parsing Lambda FASTQ\n",
      "The FASTQ file format is commonly used to store deep sequences reads data. It is similar to the FASTA format, but includes additional information. Each record is represented by four lines:\n",
      "- Line 1 begins with a '@' character and is followed by a sequence identifier and an optional description (like a FASTA title line).\n",
      "- Line 2 is the raw sequence letters.\n",
      "- Line 3 is just a '+' character\n",
      "- Line 4 encodes the quality values for the sequence in Line 2, and must contain the same number of symbols as letters in the sequence.  \n",
      "Sequence quality is encoded with characters from the list below:\n",
      "<pre> !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ </pre>\n",
      "Where '!' represents the lowest quality, equivalent to a score of 1, and '~' is the highest quality with a score of 94.  \n",
      "The function given below translates the characters into their corresponding scores and returns a dictionary which you can use later. Make sure you understand how to work with this dictionary before proceeding. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def creates_scores_dict():\n",
      "    scores_string = \"\"\"!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\"\"\"\n",
      "    scores_dict = {}\n",
      "    for s in range(len(scores_string)):\n",
      "        scores_dict[scores_string[s]] = s + 1\n",
      "    return scores_dict\n",
      "\n",
      "scores_dict = creates_scores_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The file /files_for_hw/lambda_reads.fq contains 10,000 reads from the sequencing of the lambda phage. We would like to discard low quality reads. A low quality read is defined as one with a mean score lower than some predefined threshold.  \n",
      "a) Write a function that receives a read quality string and returns the mean score (float) of the read. For example, the quality string:\n",
      "<pre>!!!!!</pre>\n",
      "is equivalent to the scores 1,1,1,1,1, and thus the mean is 1. However, the string:\n",
      "<pre>49@5<*>=E</pre>\n",
      "is equivalent to the scores 20,25,32,21,28,10,30,29,37 and has a mean of 25.77."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calculate_mean_score(read_quality_string):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "b) Write a function that parses a FASTQ file. It receives a path to a FASTQ file and returns a _dictionary_ where the keys are the sequences and the values are the mean scores of the sequences. Use the function on the provided file.  \n",
      "* It is recommended to use the `readline()` method (although other solutions are also possible)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_FASTQ(file):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "# parse lambda reads file  \n",
      "lambda_reads_file = \"files_for_hw/lambda_reads.fq\"\n",
      "lambda_seqs_dict = parse_FASTQ(lambda_reads_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "c) Write a function that takes the output from section b and a score cutoff (integer/float) and prints out the sequences with scores higher than the cutoff. Each sequence will be printed in a separate line (no need to keep the FASTQ format). Try different cutoffs (5,10,20) on the Lambda phage reads."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_reads(seqs_dict,cutoff,out_file):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "# run on Lambda reads\n",
      "lambda_filtered_file = \"files_for_hw/lambda_filtered_reads.txt\"\n",
      "filter_reads(lambda_seqs_dict,10,lambda_filtered_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Endangered turtles\n",
      "In this question, we will work on data from the [Global Biodiversity Information Facility](http://www.gbif.org/) (GBIF). This server holds  lots of data about occurences of organisms around the world.  \n",
      "Our goal will be to get the coordinates of observations of endangered turtles species in the Southern hemisphere.  \n",
      "The CSV files under /files_for_hw/gbif_files, named GBIF1.csv, GBIF2.csv etc, contain observations data for various turtles genera. Each record is an observation, and contains information such as the species name and the coordinates of the observation.  \n",
      "a) The first step in the analysis will be to append all CSV files into one file, to make processing easier. Write a function that receives a list of files and appends them (i.e inserts all records from all files into one file). Remember to include the headers line only once. Use the function to create a unified csv file.  \n",
      "\n",
      "__Note__: The function does not return anything!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def append_csvs(csvs_list,out_csv):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "# create unified file\n",
      "dir = \"files_for_hw/gbif_files/\n",
      "files_list = []\n",
      "for i in range(1,23):\n",
      "    file = dir + 'GBIF' + str(i) + '.csv'\n",
      "    files_list.append(file)\n",
      "unified_csv = dir + 'unified.csv'\n",
      "append_csvs(???,???)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "b) The file files_for_hw/gbif_files/endangered_turtles.txt contains a list of endangered turtles species from [The IUCN Red List of Threatened Species](http://www.iucnredlist.org/). Write a function that reads the file and returns a list of the species it includes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_species_list(file):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "endamgered_turtles_file = dir + 'endangered_turtles.txt'\n",
      "endangered_turtles_list = get_species_list(endamgered_turtles_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "c) We will now use the unified CSV file and endangered species list to create a filtered CSV, containing only the records we are interested in: those of endangered species, observed in the Southern hemisphere (i.e. in latitude < 0).  \n",
      "Write a function that receives the unified file, species list, maximum latitude and output file, and print out only the records which satisfy these conditions (no return value is needed)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_records(in_csv_file, species_list, max_lat, out_csv_file):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "filtered_file = dir + 'endangered.csv'\n",
      "filter_records(???,???,???,???)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Regex drills\n",
      "In this question, you don't have to write a real code, just write the regular expression you'd use within the quotation marks.  \n",
      "a) Write a regex that will match strings containing any kind of number: positive/negative, integer/float etc. For example, all of the following should be matched: 7 , -3 , 6.14 , -0.00054  \n",
      "b) Write a regex that will match strings that __end__ with a number between 100 and 199, followed by a '.' __or__ a '\\' character.  \n",
      "c) Write a regex that will match strings containing prices in dollars, such as '100$', '2.99$', '500.90$', but not '7.656$' or '80.0001$'.  \n",
      "d) Write a regex that will match strings beginning with 3 to 8 uppercase letters, followed by at least 4 characters, which can be anything but '%' or '!', and end with 'XY' or 'QW'.  \n",
      "* It is highly recommended to use [The regex Coach](http://www.weitz.de/regex-coach/) for this question."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## a)\n",
      "re.compile(r'')\n",
      "## b)\n",
      "re.compile(r'')\n",
      "## c)\n",
      "re.compile(r'')\n",
      "## d)\n",
      "re.compile(r'')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plant names\n",
      "A full scientific name of a plant species consists of a genus name, a species name and an authority (usually a short for the name of the person to first describe the species). For example, in _Arabidopsis thaliana (L.) Heynh._ 'Arabidopsis' is the genus, 'thaliana' is the species and '(L.) Heynh.' is the authority. The genus always begins with a capital letter, followed by one or more lower case letters. The species is all lowercasse. The authority can include any character. In addition, a name may (or may not) include an infraspecific rank. This is added after the species name, and consists of an _epithet_ which is either 'subsp.' (for subspecies) or 'var.' (for variety). The epithet is followed by the name of the infraspecific rank. For example, in Fraxinus americana var. acuminata (Lam.) K.Koch , the genus is 'Fraxinus', the species is 'americana', the infraspecies is 'var. acuminata' and the authority is '(Lam.) K.Koch'.  \n",
      "The file /files_for_hw/plant_names.txt contains a list of plant names. The goal is to break these names into their components. Write a program that reads the names from the file and prints a new CSV file with the following column names: Genus, Species, Infraspecific and Authority. Each plant name in the provided list should then be processed (use regular expression\\s) and its components inserted into the CSV file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### your code here\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}