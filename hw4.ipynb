{
 "metadata": {
  "name": "",
  "signature": "sha256:ac3991a197abb7d69bb1ff6fde49db1ab3a9aa36842b217177528f32215214fe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parsing Lambda FASTQ\n",
      "The FASTQ file format is commonly used to store deep sequences reads data. It is similar to the FASTA format, but includes additional information. Each record is represented by four lines:\n",
      "- Line 1 begins with a '@' character and is followed by a sequence identifier and an optional description (like a FASTA title line).\n",
      "- Line 2 is the raw sequence letters.\n",
      "- Line 3 is just a '+' character\n",
      "- Line 4 encodes the quality values for the sequence in Line 2, and must contain the same number of symbols as letters in the sequence.  \n",
      "Sequence quality is encoded with characters from the list below:\n",
      "<pre> !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ </pre>\n",
      "Where '!' represents the lowest quality, equivalent to a score of 1, and '~' is the highest quality with a score of 94.  \n",
      "The function given below translates the characters into their corresponding scores and returns a dictionary which you can use later. Make sure you understand how to work with this dictionary before proceeding. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def creates_scores_dict():\n",
      "    scores_string = \"\"\"!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\"\"\"\n",
      "    scores_dict = {}\n",
      "    for s in range(len(scores_string)):\n",
      "        scores_dict[scores_string[s]] = s\n",
      "    return scores_dict\n",
      "\n",
      "scores_dict = creates_scores_dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The file /files_for_hw/lambda_reads.fq contains 10,000 reads from the sequencing of the lambda phage. We would like to discard low quality reads. A low quality read is defined as one with a mean score lower than some predefined threshold.  \n",
      "a) Write a function that receives a read quality string and returns the mean score (float) of the read. For example, the quality string:\n",
      "<pre>!!!!!</pre>\n",
      "is equivalent to the scores 1,1,1,1,1, and thus the mean is 1. However, the string:\n",
      "<pre>49@5<*>=E</pre>\n",
      "is equivalent to the scores 19,24,31,20,27,9,29,28,36 and has a mean of 24.77."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calculate_mean_score(read_quality_string):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "b) Write a function that parses a FASTQ file. It receives a path to a FASTQ file and returns a _dictionary_ where the keys are the sequences and the values are the mean scores of the sequences. Use the function on the provided file.  \n",
      "* It is recommended to use the `readline()` method (although other solutions are also possible)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_FASTQ(file):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "# parse lambda reads file  \n",
      "lambda_reads_file = \"/files_for_hw/lambda_reads.fq\"\n",
      "lambda_seqs_dict = parse_FASTQ(lambda_reads_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Endangered turtles\n",
      "In this question, we will work on data from the [Global Biodiversity Information Facility](http://www.gbif.org/) (GBIF). This server holds  lots of data about occurences of organisms around the world.  \n",
      "Our goal will be to get the coordinates of observations of endangered turtles species in the Southern hemisphere.  \n",
      "The CSV files under /files_for_hw/gbif_files, named GBIF1.csv, GBIF2.csv etc, contain observations data for various turtles genera. Each record is an observation, and contains information such as the species name and the coordinates of the observation.  \n",
      "a) The first step in the analysis will be to append all CSV files into one file, to make processing easier. Write a function that receives a list of files and appends them (i.e inserts all records from all files into one file). Remember to include the headers line only once. Use the function to create a unified csv file.  \n",
      "\n",
      "__Note__: The function does not return anything!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def append_csvs(csvs_list,out_csv):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "# create unified file\n",
      "dir = \"files_for_hw/gbif_files/\n",
      "files_list = []\n",
      "for i in range(1,23):\n",
      "    file = dir + 'GBIF' + str(i) + '.csv'\n",
      "    files_list.append(file)\n",
      "unified_csv = dir + 'unified.csv'\n",
      "append_csvs(???,???)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "b) The file files_for_hw/gbif_files/endangered_turtles.txt contains a list of endangered turtles species from [The IUCN Red List of Threatened Species](http://www.iucnredlist.org/). Write a function that reads the file and returns a list of the species it includes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_species_list(file):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "endamgered_turtles_file = dir + 'endangered_turtles.txt'\n",
      "endangered_turtles_list = get_species_list(endamgered_turtles_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "c) We will now use the unified CSV file and endangered species list to create a filtered CSV, containing only the records we are interested in: those of endangered species, observed in the Southern hemisphere (i.e. in latitude < 0).  \n",
      "Write a function that receives the unified file, species list, maximum latitude and output file, and print out only the records which satisfy these conditions (no return value is needed)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_records(in_csv_file, species_list, max_lat, out_csv_file):\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "filtered_file = dir + 'endangered.csv'\n",
      "filter_records(???,???,???,???)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}